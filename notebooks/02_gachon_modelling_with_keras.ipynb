{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model language proficiency based on text characteristics using neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../movielingo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from movielingo.config import processed_data_dir\n",
    "df = pd.read_csv(processed_data_dir / 'gachon_features_1706_2000.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['L2_proficiency'] = df['L2_proficiency'].astype(float)\n",
    "df['L2_proficiency'] = df['L2_proficiency']/1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # df.hist(figsize=(20,20), bins = 20, color = 'pink');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recode continuous English proficiency scores into classes\n",
    "\n",
    "- 0: Beginner + Intermediate\n",
    "- 1: Upper-Intermediate + Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toeic2cefr(row):\n",
    "    if row.L2_proficiency < 120/1000:\n",
    "        return 4\n",
    "    elif row.L2_proficiency < 255/1000:\n",
    "        return 0\n",
    "    elif row.L2_proficiency < 550/1000:\n",
    "        return 0\n",
    "    elif row.L2_proficiency < 785/1000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cefr'] = df.apply(toeic2cefr, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cefr.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.cefr != 4].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2_proficiency</th>\n",
       "      <th>n_uniq_lemmas</th>\n",
       "      <th>mean_sent_len</th>\n",
       "      <th>median_sent_len</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>mean_wf_lemma</th>\n",
       "      <th>mean_wf_token</th>\n",
       "      <th>mean_n_uniq_rare_lemmas</th>\n",
       "      <th>n_unique_verb_forms</th>\n",
       "      <th>...</th>\n",
       "      <th>vp_t</th>\n",
       "      <th>c_t</th>\n",
       "      <th>cp_t</th>\n",
       "      <th>cp_c</th>\n",
       "      <th>cn_t</th>\n",
       "      <th>cn_c</th>\n",
       "      <th>ct_t</th>\n",
       "      <th>t_s</th>\n",
       "      <th>dc_t</th>\n",
       "      <th>dc_c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cefr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>...</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      L2_proficiency  n_uniq_lemmas  mean_sent_len  median_sent_len  \\\n",
       "cefr                                                                  \n",
       "0               1024           1024           1024             1024   \n",
       "1                929            929            929              929   \n",
       "\n",
       "      sd_sent_len  mean_word_len  mean_wf_lemma  mean_wf_token  \\\n",
       "cefr                                                             \n",
       "0            1024           1024           1024           1024   \n",
       "1             929            929            929            929   \n",
       "\n",
       "      mean_n_uniq_rare_lemmas  n_unique_verb_forms  ...  vp_t   c_t  cp_t  \\\n",
       "cefr                                                ...                     \n",
       "0                        1024                 1024  ...  1024  1024  1024   \n",
       "1                         929                  929  ...   929   929   929   \n",
       "\n",
       "      cp_c  cn_t  cn_c  ct_t   t_s  dc_t  dc_c  \n",
       "cefr                                            \n",
       "0     1024  1024  1024  1024  1024  1024  1024  \n",
       "1      929   929   929   929   929   929   929  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('cefr').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L2_proficiency</th>\n",
       "      <th>n_uniq_lemmas</th>\n",
       "      <th>mean_sent_len</th>\n",
       "      <th>median_sent_len</th>\n",
       "      <th>sd_sent_len</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>mean_wf_lemma</th>\n",
       "      <th>mean_wf_token</th>\n",
       "      <th>mean_n_uniq_rare_lemmas</th>\n",
       "      <th>n_unique_verb_forms</th>\n",
       "      <th>...</th>\n",
       "      <th>c_t</th>\n",
       "      <th>cp_t</th>\n",
       "      <th>cp_c</th>\n",
       "      <th>cn_t</th>\n",
       "      <th>cn_c</th>\n",
       "      <th>ct_t</th>\n",
       "      <th>t_s</th>\n",
       "      <th>dc_t</th>\n",
       "      <th>dc_c</th>\n",
       "      <th>cefr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.78</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>13.125000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>3.479853</td>\n",
       "      <td>105.0</td>\n",
       "      <td>-7.317674</td>\n",
       "      <td>-7.437929</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.78</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.886134</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-7.201932</td>\n",
       "      <td>-7.301136</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.154545</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.78</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.035556</td>\n",
       "      <td>105.0</td>\n",
       "      <td>-6.950617</td>\n",
       "      <td>-6.997663</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>...</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78</td>\n",
       "      <td>1.966667</td>\n",
       "      <td>13.625000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.081478</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-7.321971</td>\n",
       "      <td>-7.601701</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>...</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.637500</td>\n",
       "      <td>7.776923</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.78</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.841783</td>\n",
       "      <td>123.0</td>\n",
       "      <td>-6.982382</td>\n",
       "      <td>-7.038975</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   L2_proficiency  n_uniq_lemmas  mean_sent_len  median_sent_len  sd_sent_len  \\\n",
       "0            0.78       2.033333      13.125000             12.5     3.479853   \n",
       "1            0.78       2.100000      14.571429             15.0     3.886134   \n",
       "2            0.78       1.900000      15.000000             16.0     4.035556   \n",
       "3            0.78       1.966667      13.625000             10.5     6.081478   \n",
       "4            0.78       2.166667      12.300000              9.5     6.841783   \n",
       "\n",
       "   mean_word_len  mean_wf_lemma  mean_wf_token  mean_n_uniq_rare_lemmas  \\\n",
       "0          105.0      -7.317674      -7.437929                 0.016393   \n",
       "1          102.0      -7.201932      -7.301136                 0.015873   \n",
       "2          105.0      -6.950617      -6.997663                 0.017544   \n",
       "3          109.0      -7.321971      -7.601701                 0.016949   \n",
       "4          123.0      -6.982382      -7.038975                 0.015385   \n",
       "\n",
       "   n_unique_verb_forms  ...       c_t      cp_t      cp_c       cn_t  \\\n",
       "0             0.047619  ...  2.000000  0.012500  0.006250   1.375000   \n",
       "1             0.058824  ...  1.571429  0.014286  0.009091   0.242857   \n",
       "2             0.038095  ...  2.142857  0.028571  0.013333   0.242857   \n",
       "3             0.045872  ...  1.625000  0.000000  0.000000  12.637500   \n",
       "4             0.032520  ...  1.700000  0.000000  0.000000   0.290000   \n",
       "\n",
       "       cn_c      ct_t   t_s      dc_t      dc_c  cefr  \n",
       "0  0.687500  0.062500  10.0  0.100000  0.050000     1  \n",
       "1  0.154545  0.042857  10.0  0.042857  0.027273     1  \n",
       "2  0.113333  0.085714  10.0  0.100000  0.046667     1  \n",
       "3  7.776923  0.050000  10.0  0.050000  0.030769     1  \n",
       "4  0.170588  0.060000  10.0  0.080000  0.047059     1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=19)\n",
    "\n",
    "for train_index, test_index in split.split(df, df.cefr):\n",
    "    learners_train = df.loc[train_index]\n",
    "    learners_test = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L2_proficiency', 'n_uniq_lemmas', 'mean_sent_len', 'median_sent_len',\n",
       "       'sd_sent_len', 'mean_word_len', 'mean_wf_lemma', 'mean_wf_token',\n",
       "       'mean_n_uniq_rare_lemmas', 'n_unique_verb_forms', 'n_unique_past_verbs',\n",
       "       'n_unique_adj', 'n_unique_adv', 'n_unique_prepos', 'n_unique_modals',\n",
       "       'n_wh', 'mls', 'mlt', 'mlc', 'c_s', 'vp_t', 'c_t', 'cp_t', 'cp_c',\n",
       "       'cn_t', 'cn_c', 'ct_t', 't_s', 'dc_t', 'dc_c', 'cefr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learners_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners_train.drop(columns=[\"L2_proficiency\"], inplace = True)\n",
    "learners_test.drop(columns=[ \"L2_proficiency\"], inplace = True)\n",
    "learners_train_labels = learners_train.cefr\n",
    "learners_train = learners_train.drop('cefr', axis = 1)\n",
    "learners_test_labels = learners_test.cefr\n",
    "learners_test = learners_test.drop('cefr', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learners_train_labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cat_names = []\n",
    "all_num_names = learners_train.columns\n",
    "learners_cat = learners_train[all_cat_names]\n",
    "learners_num = learners_train[all_num_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = \"constant\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('one_hot', OneHotEncoder()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attrib = all_num_names\n",
    "cat_attrib = all_cat_names \n",
    "\n",
    "prep_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attrib),\n",
    "    ('cat', cat_pipeline, cat_attrib),\n",
    "],sparse_threshold=0.06) # for dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = prep_pipeline.fit_transform(learners_train)\n",
    "y_tr = keras.utils.to_categorical(learners_train_labels.values, num_classes= 2)\n",
    "X_te = prep_pipeline.transform(learners_test)\n",
    "y_te = keras.utils.to_categorical(learners_test_labels.values, num_classes= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If predicting 4 classes: deal with imbalance by either oversampling or weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "# from imblearn.over_sampling import (SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC,\n",
    "#                                     KMeansSMOTE)\n",
    "# X_tr, y_tr = SMOTE(random_state=42).fit_resample(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=1082    0\n",
      "1433    1\n",
      "1043    1\n",
      "1087    0\n",
      "1304    0\n",
      "       ..\n",
      "1731    1\n",
      "1847    0\n",
      "50      1\n",
      "1706    0\n",
      "1553    0\n",
      "Name: cefr, Length: 1562, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(learners_train_labels),\n",
    "#                                                  learners_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\",\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-7),\n",
    "                    ),\n",
    "        layers.LeakyReLU(alpha=0.3),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(32, activation=\"relu\",\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=0, l2=1e-7),\n",
    "                    ),\n",
    "        layers.LeakyReLU(alpha=0.3),\n",
    "      \n",
    "        layers.Dense(2, activation = \"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=1e-3),\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "1562/1562 [==============================] - 0s 62us/step - loss: 0.6643 - categorical_accuracy: 0.6101\n",
      "Epoch 2/2500\n",
      "1562/1562 [==============================] - 0s 63us/step - loss: 0.6643 - categorical_accuracy: 0.5858\n",
      "Epoch 3/2500\n",
      "1562/1562 [==============================] - 0s 64us/step - loss: 0.6647 - categorical_accuracy: 0.6056\n",
      "Epoch 4/2500\n",
      "1562/1562 [==============================] - 0s 60us/step - loss: 0.6594 - categorical_accuracy: 0.6063\n",
      "Epoch 5/2500\n",
      "1562/1562 [==============================] - 0s 63us/step - loss: 0.6634 - categorical_accuracy: 0.6088\n",
      "Epoch 6/2500\n",
      "1562/1562 [==============================] - 0s 65us/step - loss: 0.6563 - categorical_accuracy: 0.6223\n",
      "Epoch 7/2500\n",
      "1562/1562 [==============================] - 0s 56us/step - loss: 0.6618 - categorical_accuracy: 0.6069\n",
      "Epoch 8/2500\n",
      "1562/1562 [==============================] - 0s 95us/step - loss: 0.6630 - categorical_accuracy: 0.5986\n",
      "Epoch 9/2500\n",
      "1562/1562 [==============================] - 0s 58us/step - loss: 0.6643 - categorical_accuracy: 0.5922\n",
      "Epoch 10/2500\n",
      "1562/1562 [==============================] - 0s 61us/step - loss: 0.6593 - categorical_accuracy: 0.6114\n",
      "Epoch 11/2500\n",
      "1562/1562 [==============================] - 0s 59us/step - loss: 0.6598 - categorical_accuracy: 0.6127\n",
      "Epoch 12/2500\n",
      "1562/1562 [==============================] - 0s 67us/step - loss: 0.6588 - categorical_accuracy: 0.6108\n",
      "Epoch 13/2500\n",
      "1562/1562 [==============================] - 0s 67us/step - loss: 0.6559 - categorical_accuracy: 0.5999\n",
      "Epoch 14/2500\n",
      "1562/1562 [==============================] - 0s 65us/step - loss: 0.6630 - categorical_accuracy: 0.5973\n",
      "Epoch 15/2500\n",
      "1562/1562 [==============================] - 0s 64us/step - loss: 0.6610 - categorical_accuracy: 0.6114\n",
      "Epoch 16/2500\n",
      "1562/1562 [==============================] - 0s 57us/step - loss: 0.6638 - categorical_accuracy: 0.6063\n",
      "Epoch 17/2500\n",
      "1562/1562 [==============================] - 0s 75us/step - loss: 0.6623 - categorical_accuracy: 0.5928\n",
      "Epoch 18/2500\n",
      "1562/1562 [==============================] - 0s 59us/step - loss: 0.6642 - categorical_accuracy: 0.5871\n",
      "Epoch 19/2500\n",
      "1562/1562 [==============================] - 0s 62us/step - loss: 0.6592 - categorical_accuracy: 0.6031\n",
      "Epoch 20/2500\n",
      "1562/1562 [==============================] - 0s 66us/step - loss: 0.6616 - categorical_accuracy: 0.6069\n",
      "Epoch 21/2500\n",
      "1562/1562 [==============================] - 0s 63us/step - loss: 0.6679 - categorical_accuracy: 0.5973\n",
      "Epoch 22/2500\n",
      "1562/1562 [==============================] - 0s 73us/step - loss: 0.6580 - categorical_accuracy: 0.5992\n",
      "Epoch 23/2500\n",
      "1562/1562 [==============================] - 0s 58us/step - loss: 0.6545 - categorical_accuracy: 0.6127\n",
      "Epoch 24/2500\n",
      "1562/1562 [==============================] - 0s 157us/step - loss: 0.6616 - categorical_accuracy: 0.5999\n",
      "Epoch 25/2500\n",
      "1562/1562 [==============================] - 0s 117us/step - loss: 0.6643 - categorical_accuracy: 0.6133\n",
      "Epoch 26/2500\n",
      "1562/1562 [==============================] - 0s 77us/step - loss: 0.6562 - categorical_accuracy: 0.6140\n",
      "Epoch 27/2500\n",
      "1562/1562 [==============================] - 0s 66us/step - loss: 0.6650 - categorical_accuracy: 0.5909\n",
      "Epoch 28/2500\n",
      "1562/1562 [==============================] - 0s 41us/step - loss: 0.6521 - categorical_accuracy: 0.6127\n",
      "Epoch 29/2500\n",
      "1562/1562 [==============================] - 0s 39us/step - loss: 0.6639 - categorical_accuracy: 0.6024\n",
      "Epoch 30/2500\n",
      "1562/1562 [==============================] - 0s 48us/step - loss: 0.6612 - categorical_accuracy: 0.6101\n",
      "Epoch 31/2500\n",
      "1562/1562 [==============================] - 0s 67us/step - loss: 0.6600 - categorical_accuracy: 0.6127\n",
      "Epoch 32/2500\n",
      "1562/1562 [==============================] - 0s 66us/step - loss: 0.6614 - categorical_accuracy: 0.5992\n",
      "Epoch 33/2500\n",
      "1562/1562 [==============================] - 0s 82us/step - loss: 0.6570 - categorical_accuracy: 0.6127\n",
      "Epoch 34/2500\n",
      "1562/1562 [==============================] - 0s 56us/step - loss: 0.6563 - categorical_accuracy: 0.6184\n",
      "Epoch 35/2500\n",
      "1562/1562 [==============================] - 0s 52us/step - loss: 0.6616 - categorical_accuracy: 0.6133\n",
      "Epoch 36/2500\n",
      "1562/1562 [==============================] - 0s 83us/step - loss: 0.6596 - categorical_accuracy: 0.6146\n",
      "Epoch 37/2500\n",
      "1562/1562 [==============================] - 0s 67us/step - loss: 0.6594 - categorical_accuracy: 0.6056\n",
      "Epoch 38/2500\n",
      "1562/1562 [==============================] - 0s 68us/step - loss: 0.6616 - categorical_accuracy: 0.6037\n",
      "Epoch 39/2500\n",
      "1562/1562 [==============================] - 0s 53us/step - loss: 0.6584 - categorical_accuracy: 0.6076\n",
      "Epoch 40/2500\n",
      "1562/1562 [==============================] - 0s 66us/step - loss: 0.6589 - categorical_accuracy: 0.6191\n",
      "Epoch 41/2500\n",
      "1562/1562 [==============================] - 0s 78us/step - loss: 0.6576 - categorical_accuracy: 0.6101\n",
      "Epoch 42/2500\n",
      "1562/1562 [==============================] - 0s 70us/step - loss: 0.6573 - categorical_accuracy: 0.6120\n",
      "Epoch 43/2500\n",
      "1562/1562 [==============================] - 0s 70us/step - loss: 0.6653 - categorical_accuracy: 0.6216\n",
      "Epoch 44/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6600 - categorical_accuracy: 0.6018\n",
      "Epoch 45/2500\n",
      "1562/1562 [==============================] - 0s 108us/step - loss: 0.6544 - categorical_accuracy: 0.6178\n",
      "Epoch 46/2500\n",
      "1562/1562 [==============================] - 0s 79us/step - loss: 0.6586 - categorical_accuracy: 0.6095\n",
      "Epoch 47/2500\n",
      "1562/1562 [==============================] - 0s 57us/step - loss: 0.6610 - categorical_accuracy: 0.6095\n",
      "Epoch 48/2500\n",
      "1562/1562 [==============================] - 0s 47us/step - loss: 0.6600 - categorical_accuracy: 0.6152\n",
      "Epoch 49/2500\n",
      "1562/1562 [==============================] - 0s 50us/step - loss: 0.6538 - categorical_accuracy: 0.6261\n",
      "Epoch 50/2500\n",
      "1562/1562 [==============================] - 0s 48us/step - loss: 0.6557 - categorical_accuracy: 0.6082\n",
      "Epoch 51/2500\n",
      "1562/1562 [==============================] - 0s 49us/step - loss: 0.6588 - categorical_accuracy: 0.6063\n",
      "Epoch 52/2500\n",
      "1562/1562 [==============================] - 0s 46us/step - loss: 0.6569 - categorical_accuracy: 0.6165\n",
      "Epoch 53/2500\n",
      "1562/1562 [==============================] - 0s 54us/step - loss: 0.6543 - categorical_accuracy: 0.6076\n",
      "Epoch 54/2500\n",
      "1562/1562 [==============================] - 0s 43us/step - loss: 0.6528 - categorical_accuracy: 0.6261\n",
      "Epoch 55/2500\n",
      "1562/1562 [==============================] - 0s 42us/step - loss: 0.6596 - categorical_accuracy: 0.6133\n",
      "Epoch 56/2500\n",
      "1562/1562 [==============================] - 0s 43us/step - loss: 0.6568 - categorical_accuracy: 0.6031\n",
      "Epoch 57/2500\n",
      "1562/1562 [==============================] - 0s 40us/step - loss: 0.6560 - categorical_accuracy: 0.6095\n",
      "Epoch 58/2500\n",
      "1562/1562 [==============================] - 0s 42us/step - loss: 0.6581 - categorical_accuracy: 0.6120\n",
      "Epoch 59/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6575 - categorical_accuracy: 0.5967\n",
      "Epoch 60/2500\n",
      "1562/1562 [==============================] - 0s 54us/step - loss: 0.6564 - categorical_accuracy: 0.6108\n",
      "Epoch 61/2500\n",
      "1562/1562 [==============================] - 0s 93us/step - loss: 0.6553 - categorical_accuracy: 0.6184\n",
      "Epoch 62/2500\n",
      "1562/1562 [==============================] - 0s 63us/step - loss: 0.6538 - categorical_accuracy: 0.6114\n",
      "Epoch 63/2500\n",
      "1562/1562 [==============================] - 0s 66us/step - loss: 0.6584 - categorical_accuracy: 0.5999\n",
      "Epoch 64/2500\n",
      "1562/1562 [==============================] - 0s 68us/step - loss: 0.6550 - categorical_accuracy: 0.6229\n",
      "Epoch 65/2500\n",
      "1562/1562 [==============================] - 0s 75us/step - loss: 0.6580 - categorical_accuracy: 0.6056\n",
      "Epoch 66/2500\n",
      "1562/1562 [==============================] - 0s 109us/step - loss: 0.6533 - categorical_accuracy: 0.5999\n",
      "Epoch 67/2500\n",
      "1562/1562 [==============================] - 0s 68us/step - loss: 0.6560 - categorical_accuracy: 0.6095\n",
      "Epoch 68/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6554 - categorical_accuracy: 0.6197\n",
      "Epoch 69/2500\n",
      "1562/1562 [==============================] - 0s 53us/step - loss: 0.6546 - categorical_accuracy: 0.6204\n",
      "Epoch 70/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 0s 52us/step - loss: 0.6548 - categorical_accuracy: 0.6312\n",
      "Epoch 71/2500\n",
      "1562/1562 [==============================] - 0s 47us/step - loss: 0.6551 - categorical_accuracy: 0.6127\n",
      "Epoch 72/2500\n",
      "1562/1562 [==============================] - 0s 47us/step - loss: 0.6555 - categorical_accuracy: 0.6133\n",
      "Epoch 73/2500\n",
      "1562/1562 [==============================] - 0s 45us/step - loss: 0.6553 - categorical_accuracy: 0.6223\n",
      "Epoch 74/2500\n",
      "1562/1562 [==============================] - 0s 47us/step - loss: 0.6584 - categorical_accuracy: 0.6172\n",
      "Epoch 75/2500\n",
      "1562/1562 [==============================] - 0s 46us/step - loss: 0.6541 - categorical_accuracy: 0.6280\n",
      "Epoch 76/2500\n",
      "1562/1562 [==============================] - 0s 45us/step - loss: 0.6535 - categorical_accuracy: 0.6255\n",
      "Epoch 77/2500\n",
      "1562/1562 [==============================] - 0s 40us/step - loss: 0.6535 - categorical_accuracy: 0.6133\n",
      "Epoch 78/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6593 - categorical_accuracy: 0.5992\n",
      "Epoch 79/2500\n",
      "1562/1562 [==============================] - 0s 41us/step - loss: 0.6530 - categorical_accuracy: 0.6236\n",
      "Epoch 80/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6544 - categorical_accuracy: 0.6152\n",
      "Epoch 81/2500\n",
      "1562/1562 [==============================] - 0s 41us/step - loss: 0.6563 - categorical_accuracy: 0.6056\n",
      "Epoch 82/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6612 - categorical_accuracy: 0.6005\n",
      "Epoch 83/2500\n",
      "1562/1562 [==============================] - 0s 51us/step - loss: 0.6554 - categorical_accuracy: 0.6159\n",
      "Epoch 84/2500\n",
      "1562/1562 [==============================] - 0s 45us/step - loss: 0.6598 - categorical_accuracy: 0.6063\n",
      "Epoch 85/2500\n",
      "1562/1562 [==============================] - 0s 41us/step - loss: 0.6492 - categorical_accuracy: 0.6338\n",
      "Epoch 86/2500\n",
      "1562/1562 [==============================] - 0s 47us/step - loss: 0.6546 - categorical_accuracy: 0.6133\n",
      "Epoch 87/2500\n",
      "1562/1562 [==============================] - 0s 56us/step - loss: 0.6565 - categorical_accuracy: 0.6178\n",
      "Epoch 88/2500\n",
      "1562/1562 [==============================] - 0s 42us/step - loss: 0.6509 - categorical_accuracy: 0.6204\n",
      "Epoch 89/2500\n",
      "1562/1562 [==============================] - 0s 40us/step - loss: 0.6542 - categorical_accuracy: 0.6229\n",
      "Epoch 90/2500\n",
      "1562/1562 [==============================] - 0s 40us/step - loss: 0.6539 - categorical_accuracy: 0.6088\n",
      "Epoch 91/2500\n",
      "1562/1562 [==============================] - 0s 42us/step - loss: 0.6554 - categorical_accuracy: 0.6152\n",
      "Epoch 92/2500\n",
      "1562/1562 [==============================] - 0s 59us/step - loss: 0.6544 - categorical_accuracy: 0.6088\n",
      "Epoch 93/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6564 - categorical_accuracy: 0.6261\n",
      "Epoch 94/2500\n",
      "1562/1562 [==============================] - 0s 50us/step - loss: 0.6576 - categorical_accuracy: 0.6076\n",
      "Epoch 95/2500\n",
      "1562/1562 [==============================] - 0s 46us/step - loss: 0.6588 - categorical_accuracy: 0.6159\n",
      "Epoch 96/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6534 - categorical_accuracy: 0.6159\n",
      "Epoch 97/2500\n",
      "1562/1562 [==============================] - 0s 45us/step - loss: 0.6532 - categorical_accuracy: 0.6095\n",
      "Epoch 98/2500\n",
      "1562/1562 [==============================] - 0s 44us/step - loss: 0.6568 - categorical_accuracy: 0.6172\n",
      "Epoch 99/2500\n",
      "1562/1562 [==============================] - 0s 46us/step - loss: 0.6575 - categorical_accuracy: 0.6248\n",
      "Epoch 100/2500\n",
      "1562/1562 [==============================] - 0s 46us/step - loss: 0.6560 - categorical_accuracy: 0.6044\n",
      "Epoch 101/2500\n",
      "1562/1562 [==============================] - 0s 48us/step - loss: 0.6499 - categorical_accuracy: 0.6300\n",
      "Epoch 102/2500\n",
      "1562/1562 [==============================] - 0s 56us/step - loss: 0.6521 - categorical_accuracy: 0.6082\n",
      "Epoch 103/2500\n",
      " 128/1562 [=>............................] - ETA: 0s - loss: 0.6737 - categorical_accuracy: 0.6250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-59360d3b0694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_tr, y_tr,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=2500)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#class_weight=class_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/insight/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/envs/insight/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/anaconda3/envs/insight/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_tr, y_tr,\n",
    "          batch_size=128,\n",
    "          epochs=2500)\n",
    "#class_weight=class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 0s 77us/step\n",
      "test_acc:  0.6138107180595398\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_te, y_te)\n",
    "print('test_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67804878, 0.32195122],\n",
       "       [0.45698925, 0.54301075]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_te.argmax(axis=1), y_pred.argmax(axis=1), normalize = 'true')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "conf = sns.heatmap(matrix, vmin=0, vmax=1, annot=True, linewidths=1, cmap=\"YlGnBu\")\n",
    "conf.set(xticklabels=['Low', 'High'], yticklabels=['Low','High'], ylabel = 'True', xlabel = 'Predicted');\n",
    "plt.savefig('confusion_matrix.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
